dataset: 'shakespeare'
eval_steps: 1000
gradient_accumulation_steps: 4
logging_dir: 'logs'
logging_steps: 100
learning_rate: 0.001
num_train_epochs: 1
out_dir: 'outputs/shakespeare_1m'
per_device_eval_batch_size: 2
per_device_train_batch_size: 2
report_to: 'none'
run_id: 'run1'
save_strategy: 'no'
warmup_steps: 100
weight_decay: 0.1